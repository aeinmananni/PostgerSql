-- Developing an Intuitive Understanding of Cost
-- خب ما میخواهیم در این بخش هزینه ای که برای هر پرس و جو صرف میکنیم رو برسی کنیم
-- ممکن است این هزینه چندثانیه و یا میلی ثانیه باشد
-- این فقط یک تعریف کاری است که انجام میوشد اما از نظر فنی 100% درست نیست


اما همین تعریف به اندازه کافی برای درک هزینه های صرف شده توسط کوئری ها کافی است

خب ما مرحله برنامه ریزی در پشت صحنه اجرا کوئری هارو برسی کردیم
که قصد دارد یک برنامه پرس و جو را تهیه کند و یا اساسا اون رو تولید کنه
که راهی برای اجرا کوئری ها است

بنابراین شاید جستو و جو برای پیدا کردن شناسه خاصی از کاربران باشد
و سپس با استفاده از نسانه گر هایی که داخلش وجود داره
برای باز کردن پرونده کاربر و بارگیری صفحات مناسب در انجا
واکشی و از فهرست خارج شود

و حالا شادی برنامه ریز تصمیم بگیرد که یک روش معتبر
دیگر برای اجرا این پرس و جو اینه که  به همه کاربران پرونده
نگاه کن و همه ان هارو جست و جو کن
با توجه به سناریویی که مطرح شد احتمالا استفاده از ایندکس ها
میتونه راهی کار امد تر و سریع تر برای پرس و جو ها باشه

خب در نهاییت ما میتونیم برسیم به این قضیه که چطوری پلنر ها میتونن فرایند جست و جو رو 
سریع تر کنن
و معرفی دوعملی که بدون اجرا خود پر سو جو میتونه کار امد باشه

خب در مرحله اول بیایم برسی کنیم پیدا کردن یک کاربر خاص رو با استفاده از ایندکس تعریف شده
برای اون ستون
و سپس داخل شاخص و به فایل هارددیسک کاربر بریم و کاربر مناسب رو بارگیری کنیم

-- =============================================================================

1-Find the ID,s of users who have username of 'X'
درمحله اول میخوایم گره ریشه خودمون رو بدتس بیاریم
و بعد از برسی گره ها تصمیم میگیریم کدام کاربر مناسب است و ان را پیدا میکنیم
و درنهایت این پرسش مارو وارد هیپ فایل میکنه و در بلوک مورد نظر اون فهرست رو پیدا میکنه

خب حالا بعد از پیدا کردن گره نگاهی به فرزندان ان می اندازیم

2-
==> Get Root node
|
|
|
==> Jump to some random child page
|
|
|
==> Process the values in that node

    ----------------------------------
   3- Open users heapfile

  4-  Jump to each block that has
    the useres we are looking  for


حالا درنظر بگیریم اگر از شاخص استفاده نمیکردیم چه اتفاقی می افتاد

1- Open the users heapfile
2- load all users from the first block
3- proccess each user see if it contains the correct username
4- Repeat the process for the next block

ابتدا هارددیسک رو باز میکردیم
همه کاربرهارو توی بلوک اول بارگیری میکردیم
و درواقع این همون کاری هست که قبل از ایندکس کردن ستون مرود نظر اتفاق می افتاد

و زمانی که همه کاربر هارو از بلوک اول پردازش کردیممیخوایم که به بلوک بعدی بریم
تا بتونیم اون کاربر مورد نظر رو پیدا کنیم

بنابر این من میخوام نوعی ارزش رو به هرکدوم از این مراحل و یا هر یک از این عملیات ها
اختصاص بدم

تعدا صفحاتی که باید از هارد دیسک بارگیری کنیم
و باید گره های مختلفی را برسی کنیم و از بعضی از گره های
فرزندان صرفه نظر میکنیم و همه کاربران را بارگیری میکنیم
و سپس میخوایم برخی از بلوک های خاص رو برسی کنیم

-- خب بیاید فرض کنیم توی هیپ فایل 100 صفحه وجود دارد 
و میخوایم راجع به سیاست بارگیری این صد صفحه صحبت کنبم
در واقع زمانی که ما از سیاست ایندکس گذاری برای بارگیری استفاده میکنیم بارگیری با ضریب پنجاه صفحه کمتر صورت میگیرد
و درواقع با سرعت در حال گشتن بین هر رکود برای یافتن کوئری مورد نظر است


--Calculating Cost by Hand



ما توی این محاسبه میخوایم برسی کنیم پردازش یک ردیف
به اندازه پردازش یک صفحه گرونه
بنابر این اگر ما صد ردیف پردازش کنیم معادل پردازش یک صفحه است

ما میخوایم بگیم چگونه میشه یک نوع تخمیل یا نوع هزینه ای رو
به چقدر گران قیمت اختصاص بدیم

(# pages) * 1.0 + (#rows) * 0.01

خب حالا میخوام مقدایر فرضی رو جایگذاری کنبم

(985) * 1.0 + (60410) * 0.01 = 1589.1;

پس میتونیم دریابیم پردازش یک ردیف به اندازه پردازش یک صفحه یک درصد گران است
بنابراین ما یک درصد دلخواه رو محاسبه کردیم





--  A Touch More on Costs

خب حالا مشاهده میکنیم معادلات کلملا واقعی برای هرمرحله از پرس و جوی دلخواه ما اورده شده است

COST = 
       + (#pages read sequentially) * seq_page_cost => (1.0) گرفتن صفحات به صورت متوالی و ضرب انها و فاکتور هزینه ای ان ها

       + (# pages read at random) * random_page_cost => (4.0)تعداد صفحاتی که به صورت تصادفی اضافه میکنیم وتوسط اون نوع صفحه تصادفی رو ضرب میکنیم

       + (# rows scanned) * cpu_tuple_cost => (0.01) قدرت پردازش مورد نیاز برای برخود با یک تاپل توسط یک سی پس یو

       + (#index entries scanned) * cpu_index_tuple_cost => (0.005) یک شاخص ارزیابی و یک اپراتور واحد

       + (#times function/operator evaluated) * cpu_operator_cost => (0.0025) و بنابراین پردازش اپراتور هایی ماند ضرب و تقسیم و تفریق و غیره




-- Startup vs Total Costs

در این مرحله از برسی هزینه های اجرا کوئری درواقع داریم برسی میکنیم
که اسکن توسط یک ایندکس چه مراحلی رو طی میکنه

ابتدا ایندکس پرس وجو میشه و خروجیش به نوعی هش میره و برخی از داده ها باهم ترکیب میشن
با اسکن متوالی

اسکن متوالی به این معناست که میخوایم پرونده پشته خودمون رو
بازکنیم  و یک صفحه رو بخونیم و تمام ردیف هارو داخل اون پردازش کنیم
و بازم بخوایم به صفحه بعدی بریم و تمام ردیف ها و غیره رو پردازش کنیم


هنگامی که همه ردیف هارو در یک صفحه جداگونه پردازش میکنیم
تعدادی از ردیف هارو اماده میکنیم
برای پردازش به مرحله بعدی در زنجیره ما

پس بنابراین اسکن متوالی اولین صفحه رو باز میکنه و شروع به پردازش همه میکنه
پس ما میتونیم در این صورت با موارد اسکن شده ارتباط برقرا کنیمو میتونیم بلافاصله از اون ها گزارشی تهیه کنیم
و سپس مت قادر به انتشار ان ردیف ها برای پیوستن به هش هستیم
پس به نوعی میتونیم بگیم در بسیاری از مراحل مختلف پردازش ما درحال پردازش های طولانی هستیم

عملیاتی که در بسیاری از ردیف های مختلف کارمیکنیم
در بیساری از موارد زمانی که بلافاصله یک ردیف رو گرفتیم میتونیم اون رو منتشر کنیم
پس بنابراین ما هزینه کمتری رو در بخش اسکن متوالی مشاهده میکنیم 
چون این هزینئه فقط برای رسیدن به ردیف اول است


-- Costs Flow Up
برسی در هش جوین که هزینه راه اندازی توی اون صفره ولی
در خروجی ما هزینه ای رو برای این ایتم مشاهده میکنیم
پس این هزینه داره ازکجا میاد ؟

درواقع اگر نگاهی به گره والدین بندازیم
این گره مربوط به والدین این بخش است
ما هزینه او گره والدین رو به عنوان مجموع گره های کودک محاسبه میکنیم




-- Use My Index!

SELECT * FROM instagram.likes

CREATE INDEX likes_created_at_idx ON instagram.likes(created_at)

EXPLAIN SELECT * FROM instagram.likes
ORDER BY created_at DESC